{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PySpark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#Create SparkSession\n",
    "spark = SparkSession.builder.appName(\"Capstone Analytics Samples\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_immigration = spark.read.parquet('tables/fact_immigration')\n",
    "dim_immigrant_person = spark.read.parquet('tables/dim_immigrant_person')\n",
    "dim_city = spark.read.parquet('tables/dim_city')\n",
    "dim_time = spark.read.parquet('tables/dim_time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tempory views for the queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_immigration.createOrReplaceTempView(\"fact_immigration_table\")\n",
    "dim_immigrant_person.createOrReplaceTempView(\"immigrant_table\")\n",
    "dim_city.createOrReplaceTempView(\"dim_city_table\")\n",
    "dim_time.createOrReplaceTempView(\"dim_time_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foreign_born_inhabitants = spark.sql(\"\"\"\n",
    "            SELECT DISTINCT\n",
    "                f.cicid as immigrant_id,\n",
    "                f.i94cit,\n",
    "                c.city_code,\n",
    "                c.city_name,\n",
    "                c.foreign_born\n",
    "            FROM dim_city_table c\n",
    "            JOIN fact_immigration_table f\n",
    "                ON f.cicid = c.city_code\n",
    "            GROUP BY c.city_name, c.foreign_born\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrivals_by_weekday = spark.sql(\"\"\"\n",
    "    SELECT t.day_of_week, COUNT(*) as count\n",
    "    FROM fact_immigration_table i\n",
    "    INNER JOIN dim_city_table c ON i.i94port = c.city_code\n",
    "    INNER JOIN dim_time_table t ON i.arrival_ts = t.ts\n",
    "    WHERE t.year=2016 AND t.month=2\n",
    "    GROUP BY t.day_of_week\n",
    "    ORDER BY t.day_of_week\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_used_ports = spark.sql(\"\"\"\n",
    "    SELECT c.city_code, c.port_state, COUNT(*) as count\n",
    "    FROM fact_immigration i\n",
    "    INNER JOIN dim_city_table p ON i.port_id = p.port_id\n",
    "    INNER JOIN dim_time_table t ON i.arrival_ts = t.ts\n",
    "    WHERE t.year=2016 AND t.month=2\n",
    "    GROUP BY c.city_code, c.city_name\n",
    "    ORDER BY count DESC\n",
    "    LIMIT 10\n",
    "    \"\"\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "506d070d07e55b089eb1ed748d43572eb732affa4f37c1b712a8590be5eb960d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('dend')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
